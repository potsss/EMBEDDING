"""
æ–°ç”¨æˆ·å‘é‡è®¡ç®—ç¤ºä¾‹è„šæœ¬
æ¼”ç¤ºå¦‚ä½•ä¸ºæ–°ç”¨æˆ·è®¡ç®—å‘é‡è¡¨ç¤ºï¼Œå¹¶ä¸å·²æœ‰ç”¨æˆ·è¿›è¡Œç›¸ä¼¼åº¦æ¯”è¾ƒ
"""
import os
import pickle
import numpy as np
from compute_new_users import load_trained_models
from main import compute_new_user_embeddings
from config import Config, get_experiment_paths

def load_existing_user_embeddings(experiment_name):
    """
    åŠ è½½å·²æœ‰ç”¨æˆ·çš„å‘é‡è¡¨ç¤º
    """
    # è®¾ç½®å®éªŒè·¯å¾„
    Config.EXPERIMENT_NAME = experiment_name
    experiment_paths = get_experiment_paths(experiment_name, allow_existing_without_timestamp=True)
    for key, value in experiment_paths.items():
        setattr(Config, key, value)
    
    # åŠ è½½å·²æœ‰ç”¨æˆ·å‘é‡
    existing_embeddings_path = os.path.join(Config.MODEL_SAVE_PATH, f'enhanced_user_embeddings_{Config.MODEL_TYPE}.pkl')
    
    if os.path.exists(existing_embeddings_path):
        with open(existing_embeddings_path, 'rb') as f:
            existing_embeddings = pickle.load(f)
        print(f"åŠ è½½äº† {len(existing_embeddings)} ä¸ªå·²æœ‰ç”¨æˆ·çš„å‘é‡")
        return existing_embeddings
    else:
        print(f"æœªæ‰¾åˆ°å·²æœ‰ç”¨æˆ·å‘é‡æ–‡ä»¶: {existing_embeddings_path}")
        return None

def compute_user_similarity(user_embedding, existing_embeddings, top_k=5):
    """
    è®¡ç®—æ–°ç”¨æˆ·ä¸å·²æœ‰ç”¨æˆ·çš„ç›¸ä¼¼åº¦
    """
    similarities = []
    user_ids = []
    
    for user_id, embedding in existing_embeddings.items():
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarity = np.dot(user_embedding, embedding) / (
            np.linalg.norm(user_embedding) * np.linalg.norm(embedding)
        )
        similarities.append(similarity)
        user_ids.append(user_id)
    
    # æ’åºå¹¶è¿”å›top_k
    sorted_indices = np.argsort(similarities)[::-1][:top_k]
    similar_users = [(user_ids[i], similarities[i]) for i in sorted_indices]
    
    return similar_users

def main():
    """
    ä¸»å‡½æ•°ï¼šæ¼”ç¤ºæ–°ç”¨æˆ·å‘é‡è®¡ç®—å’Œç›¸ä¼¼åº¦åˆ†æ
    """
    print("="*60)
    print("æ–°ç”¨æˆ·å‘é‡è®¡ç®—å’Œç›¸ä¼¼åº¦åˆ†æç¤ºä¾‹")
    print("="*60)
    
    # é…ç½®å‚æ•°
    experiment_name = "three_vector_test"  # ä½¿ç”¨ä½ çš„å®éªŒåç§°
    new_user_behavior_path = "data/new_user_behavior.csv"
    new_user_attribute_path = "data/new_user_attributes.tsv"
    new_user_location_path = "data/new_user_base_stations.tsv"
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not all(os.path.exists(path) for path in [new_user_behavior_path, new_user_attribute_path, new_user_location_path]):
        print("é”™è¯¯ï¼šæ–°ç”¨æˆ·æ•°æ®æ–‡ä»¶ä¸å®Œæ•´")
        print("è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨ï¼š")
        print(f"- {new_user_behavior_path}")
        print(f"- {new_user_attribute_path}")
        print(f"- {new_user_location_path}")
        return
    
    # è®¾ç½®å®éªŒè·¯å¾„
    Config.EXPERIMENT_NAME = experiment_name
    experiment_paths = get_experiment_paths(experiment_name, allow_existing_without_timestamp=True)
    for key, value in experiment_paths.items():
        setattr(Config, key, value)
    
    # æ£€æŸ¥å®éªŒç›®å½•
    experiment_dir = os.path.dirname(Config.PROCESSED_DATA_PATH)
    if not os.path.exists(experiment_dir):
        print(f"é”™è¯¯ï¼šå®éªŒç›®å½•ä¸å­˜åœ¨: {experiment_dir}")
        print("è¯·å…ˆè¿è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹")
        return
    
    # 1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    print("æ­¥éª¤1: åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")
    models_data = load_trained_models(experiment_dir)
    if models_data is None:
        print("æ¨¡å‹åŠ è½½å¤±è´¥")
        return
    
    # 2. è®¡ç®—æ–°ç”¨æˆ·å‘é‡
    print("\næ­¥éª¤2: è®¡ç®—æ–°ç”¨æˆ·å‘é‡...")
    new_user_embeddings = compute_new_user_embeddings(
        behavior_model=models_data['behavior_model'],
        attribute_model=models_data['attribute_model'],
        fusion_model=models_data['fusion_model'],
        url_mappings=models_data['url_mappings'],
        attribute_info=models_data['attribute_info'],
        base_station_mappings=models_data['base_station_mappings'],
        location_model=models_data['location_model'],
        location_processor=models_data['location_processor'],
        new_user_behavior_path=new_user_behavior_path,
        new_user_attribute_path=new_user_attribute_path,
        new_user_location_path=new_user_location_path
    )
    
    if not new_user_embeddings:
        print("æ–°ç”¨æˆ·å‘é‡è®¡ç®—å¤±è´¥")
        return
    
    # 3. åŠ è½½å·²æœ‰ç”¨æˆ·å‘é‡
    print("\næ­¥éª¤3: åŠ è½½å·²æœ‰ç”¨æˆ·å‘é‡...")
    existing_embeddings = load_existing_user_embeddings(experiment_name)
    if existing_embeddings is None:
        print("æ— æ³•åŠ è½½å·²æœ‰ç”¨æˆ·å‘é‡ï¼Œè·³è¿‡ç›¸ä¼¼åº¦åˆ†æ")
        return
    
    # 4. ç›¸ä¼¼åº¦åˆ†æ
    print("\næ­¥éª¤4: è¿›è¡Œç›¸ä¼¼åº¦åˆ†æ...")
    print("="*40)
    
    for new_user_id, new_user_embedding in new_user_embeddings.items():
        print(f"\næ–°ç”¨æˆ· {new_user_id} çš„æœ€ç›¸ä¼¼ç”¨æˆ·:")
        
        # è®¡ç®—ä¸å·²æœ‰ç”¨æˆ·çš„ç›¸ä¼¼åº¦
        similar_users = compute_user_similarity(new_user_embedding, existing_embeddings, top_k=5)
        
        for i, (similar_user_id, similarity) in enumerate(similar_users, 1):
            print(f"  {i}. ç”¨æˆ· {similar_user_id}: ç›¸ä¼¼åº¦ {similarity:.4f}")
    
    # 5. ä¿å­˜ç»“æœ
    print(f"\næ­¥éª¤5: ä¿å­˜æ–°ç”¨æˆ·å‘é‡...")
    output_path = os.path.join(Config.MODEL_SAVE_PATH, f'new_user_embeddings_{Config.MODEL_TYPE}.pkl')
    with open(output_path, 'wb') as f:
        pickle.dump(new_user_embeddings, f)
    print(f"æ–°ç”¨æˆ·å‘é‡å·²ä¿å­˜åˆ°: {output_path}")
    
    # 6. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"- æ–°ç”¨æˆ·æ•°é‡: {len(new_user_embeddings)}")
    print(f"- å·²æœ‰ç”¨æˆ·æ•°é‡: {len(existing_embeddings)}")
    print(f"- å‘é‡ç»´åº¦: {len(list(new_user_embeddings.values())[0])}")
    
    print("\n" + "="*60)
    print("âœ… æ–°ç”¨æˆ·å‘é‡è®¡ç®—å’Œç›¸ä¼¼åº¦åˆ†æå®Œæˆï¼")
    print("="*60)

if __name__ == "__main__":
    main() 